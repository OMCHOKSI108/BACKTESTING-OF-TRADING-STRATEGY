{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb90095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\omcho\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\omcho\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\omcho\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\omcho\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: dhanhq in c:\\users\\omcho\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.28.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from dhanhq) (2.32.3)\n",
      "Requirement already satisfied: websockets>=12.0.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from dhanhq) (15.0.1)\n",
      "Requirement already satisfied: pyOpenSSL>=20.0.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from dhanhq) (25.0.0)\n",
      "Requirement already satisfied: cryptography<45,>=41.0.5 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from pyOpenSSL>=20.0.1->dhanhq) (44.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=20.0.1->dhanhq) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=20.0.1->dhanhq) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from requests>=2.28.1->dhanhq) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from requests>=2.28.1->dhanhq) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from requests>=2.28.1->dhanhq) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omcho\\anaconda3\\lib\\site-packages (from requests>=2.28.1->dhanhq) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn matplotlib seaborn dhanhq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2085cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 5-min data for Security ID: 26001...\n",
      "  > An API error occurred: 'dhanhq' object has no attribute 'intraday_daily_minute_charts'\n",
      "Fetching 5-min data for Security ID: 50123...\n",
      "  > An API error occurred: 'dhanhq' object has no attribute 'intraday_daily_minute_charts'\n",
      "Fetching 5-min data for Security ID: 86683...\n",
      "  > An API error occurred: 'dhanhq' object has no attribute 'intraday_daily_minute_charts'\n",
      "Fetching 5-min data for Security ID: 86682...\n",
      "  > An API error occurred: 'dhanhq' object has no attribute 'intraday_daily_minute_charts'\n",
      "Fetching 5-min data for Security ID: 86681...\n",
      "  > An API error occurred: 'dhanhq' object has no attribute 'intraday_daily_minute_charts'\n",
      "Cannot create plot: Spot data is missing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "from dhanhq import dhanhq\n",
    "\n",
    "\n",
    "# --- Dhan API Configuration (Optional: For fetching data programmatically) ---\n",
    "# Replace with your actual DhanHQ credentials.\n",
    "# Use SANDBOX for testing, or LIVE for real data.\n",
    "DHAN_CLIENT_ID = \"2510263737\"      # For Sandbox, this is 2510263737\n",
    "DHAN_ACCESS_TOKEN = \"eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbkNvbnN1bWVyVHlwZSI6IlNFTEYiLCJwYXJ0bmVySWQiOiIiLCJkaGFuQ2xpZW50SWQiOiIyNTEwMjYzNzM3Iiwid2ViaG9va1VybCI6IiIsImlzcyI6ImRoYW4iLCJleHAiOjE3NjIwOTg1Mzh9.g6vF-b4N6QQAuejhoKudaMoVKZIOXKzkCEdWTQ9NDiAayYijaZIpem1Rr1RK0QXOb-duPDkhvDy2aluLFsiPhg\" # The long token you generated\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from dhanhq import dhanhq\n",
    "import time\n",
    "\n",
    "\n",
    "# --- Analysis Configuration ---\n",
    "TARGET_DATE = '2024-01-17'\n",
    "STOCK_NAME = 'BANKNIFTY'\n",
    "\n",
    "# --- Instrument Configuration (Security IDs for Jan 17, 2024) ---\n",
    "# NOTE: These IDs can change. You must verify them from the Dhan Symbol Master list.\n",
    "# You can find the master list here: https://dhanhq.co/symbol-search/\n",
    "INSTRUMENTS = {\n",
    "    'spot': {\n",
    "        'security_id': '26001',  # Nifty Bank Index\n",
    "        'exchange_segment': 'NSE_IDX'\n",
    "    },\n",
    "    'futures': {\n",
    "        'security_id': '50123',  # BANKNIFTY JAN FUT (Example ID, please verify)\n",
    "        'exchange_segment': 'NSE_FNO'\n",
    "    },\n",
    "    # For options, we fetch a few key Put strikes that were active that day.\n",
    "    # A more advanced script would first query the option chain to find these dynamically.\n",
    "    'options': [\n",
    "        {'security_id': '86683', 'strike': 48000, 'type': 'PE'}, # BANKNIFTY 25JAN24 48000 PE (Example ID)\n",
    "        {'security_id': '86682', 'strike': 47500, 'type': 'PE'}, # BANKNIFTY 25JAN24 47500 PE (Example ID)\n",
    "        {'security_id': '86681', 'strike': 47000, 'type': 'PE'}, # BANKNIFTY 25JAN24 47000 PE (Example ID)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_intraday_data(dhan_client, security_id, exchange_segment, from_date, to_date):\n",
    "    \"\"\"Fetches 5-minute historical data using the DhanHQ API.\"\"\"\n",
    "    try:\n",
    "        print(f\"Fetching 5-min data for Security ID: {security_id}...\")\n",
    "        response = dhan_client.intraday_daily_minute_charts(\n",
    "            security_id=security_id,\n",
    "            exchange_segment=exchange_segment,\n",
    "            instrument_type='EQUITY', # Note: Type is generic for this API call\n",
    "            from_date=from_date,\n",
    "            to_date=to_date\n",
    "        )\n",
    "\n",
    "        if response and response.get('status') == 'success' and 'data' in response:\n",
    "            df = pd.DataFrame(response['data'])\n",
    "            df['timestamp'] = pd.to_datetime(df['start_Time'])\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "            # Standardize column names for consistency\n",
    "            df.rename(columns={'close': 'close', 'volume': 'volume'}, inplace=True)\n",
    "            print(f\"  > Successfully fetched {len(df)} records.\")\n",
    "            return df[['open', 'high', 'low', 'close', 'volume']]\n",
    "        else:\n",
    "            print(f\"  > Failed to fetch data: {response.get('remarks', 'No data returned')}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"  > An API error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_anomalies(df, data_name):\n",
    "    \"\"\"Engineers features and uses Isolation Forest to find anomalies.\"\"\"\n",
    "    if df is None: return None\n",
    "    print(f\"Running anomaly detection on {data_name} data...\")\n",
    "    df['Price_Change'] = df['close'].pct_change() * 100\n",
    "    df['Volume_MA'] = df['volume'].rolling(window=10).mean()\n",
    "    df['Volume_Spike'] = df['volume'] / df['Volume_MA']\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "    df['Anomaly'] = model.fit_predict(df[['Price_Change', 'Volume_Spike']])\n",
    "    return df\n",
    "\n",
    "def analyze_suspicious_options(options_df_list):\n",
    "    \"\"\"Aggregates options data and finds periods of unusually high PUT volume.\"\"\"\n",
    "    if not options_df_list: return None\n",
    "    print(\"Analyzing aggregated options data for suspicious activity...\")\n",
    "    \n",
    "    # Combine all fetched options data into a single DataFrame\n",
    "    combined_options_df = pd.concat(options_df_list)\n",
    "    \n",
    "    morning_session = combined_options_df.between_time('09:15', '12:30')\n",
    "    \n",
    "    put_volume_by_time = morning_session.groupby(morning_session.index)['volume'].sum()\n",
    "    \n",
    "    if put_volume_by_time.empty:\n",
    "        print(\"No aggregated PUT option volume found for the morning session.\")\n",
    "        return None\n",
    "\n",
    "    volume_mean = put_volume_by_time.mean()\n",
    "    volume_std = put_volume_by_time.std()\n",
    "    anomaly_threshold = volume_mean + (3 * volume_std)\n",
    "    \n",
    "    suspicious_times = put_volume_by_time[put_volume_by_time > anomaly_threshold]\n",
    "    \n",
    "    print(\"\\n--- Suspicious Options Activity Report ---\")\n",
    "    print(f\"Average 5-min Aggregated PUT Volume (9:15-12:30): {volume_mean:,.0f}\")\n",
    "    print(f\"Anomaly Threshold (Mean + 3 Std Dev): {anomaly_threshold:,.0f}\")\n",
    "    print(f\"Found {len(suspicious_times)} periods of anomalously high PUT volume.\")\n",
    "    return suspicious_times\n",
    "\n",
    "def plot_full_analysis(stock_df, futures_df, suspicious_options, stock_name, target_date):\n",
    "    \"\"\"Creates and saves an integrated plot of the analysis.\"\"\"\n",
    "    if stock_df is None:\n",
    "        print(\"Cannot create plot: Spot data is missing.\")\n",
    "        return\n",
    "        \n",
    "    print(\"Generating final analysis plot...\")\n",
    "    df_day = stock_df[stock_df.index.date == pd.to_datetime(target_date).date()]\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(20, 15), sharex=True, \n",
    "                                      gridspec_kw={'height_ratios': [3, 1, 1]})\n",
    "    fig.suptitle(f'Programmatic Analysis for {stock_name} - {target_date}', fontsize=20)\n",
    "\n",
    "    # 1. Price Chart with Anomalies\n",
    "    ax1.plot(df_day.index, df_day['close'], label='Index Price', color='dodgerblue', zorder=2)\n",
    "    stock_anomalies = df_day[df_day['Anomaly'] == -1]\n",
    "    ax1.scatter(stock_anomalies.index, stock_anomalies['close'], color='red', marker='o', s=120, zorder=5, label='Spot Market Anomaly')\n",
    "    ax1.set_ylabel('Price', fontsize=14)\n",
    "    ax1.set_title('Price Action with Spot & Options Anomalies', fontsize=16)\n",
    "    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    if suspicious_options is not None and not suspicious_options.empty:\n",
    "        for ts in suspicious_options.index:\n",
    "            ax1.axvspan(ts, ts + pd.Timedelta(minutes=5), color='purple', alpha=0.4, label='High PUT Volume Anomaly')\n",
    "    \n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax1.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "    # 2. Spot Volume Chart\n",
    "    ax2.bar(df_day.index, df_day['volume'], label='Spot Volume', color='gray', alpha=0.7, width=0.002)\n",
    "    ax2.set_ylabel('Spot Volume', fontsize=14)\n",
    "    ax2.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # 3. Futures Volume Chart\n",
    "    if futures_df is not None:\n",
    "        futures_day = futures_df[futures_df.index.date == pd.to_datetime(target_date).date()]\n",
    "        ax3.bar(futures_day.index, futures_day['volume'], label='Futures Volume', color='darkorange', alpha=0.7, width=0.002)\n",
    "    ax3.set_ylabel('Futures Volume', fontsize=14)\n",
    "    ax3.set_xlabel('Time', fontsize=14)\n",
    "    ax3.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    output_filename = f'{stock_name}_Programmatic_Analysis_{target_date}.png'\n",
    "    plt.savefig(output_filename)\n",
    "    print(f\"\\nAnalysis complete. Chart saved as '{output_filename}'\")\n",
    "\n",
    "# --- MAIN EXECUTION SCRIPT ---\n",
    "if __name__ == \"__main__\":\n",
    "    if DHAN_CLIENT_ID == \"YOUR_CLIENT_ID_HERE\" or DHAN_ACCESS_TOKEN == \"YOUR_ACCESS_TOKEN_HERE\":\n",
    "        print(\"ERROR: Please update the DHAN_CLIENT_ID and DHAN_ACCESS_TOKEN variables in the script.\")\n",
    "    else:\n",
    "        # Initialize DhanHQ Client\n",
    "        dhan = dhanhq(DHAN_CLIENT_ID, DHAN_ACCESS_TOKEN)\n",
    "        \n",
    "        # --- Step 1: Fetch all data from API ---\n",
    "        spot_df = fetch_intraday_data(dhan, **INSTRUMENTS['spot'], from_date=TARGET_DATE, to_date=TARGET_DATE)\n",
    "        time.sleep(1) # Pause to avoid hitting API rate limits\n",
    "        futures_df = fetch_intraday_data(dhan, **INSTRUMENTS['futures'], from_date=TARGET_DATE, to_date=TARGET_DATE)\n",
    "        time.sleep(1)\n",
    "\n",
    "        options_df_list = []\n",
    "        for opt in INSTRUMENTS['options']:\n",
    "            df = fetch_intraday_data(dhan, security_id=opt['security_id'], \n",
    "                                     exchange_segment='NSE_FNO', from_date=TARGET_DATE, to_date=TARGET_DATE)\n",
    "            if df is not None:\n",
    "                options_df_list.append(df)\n",
    "            time.sleep(1) # Pause between API calls\n",
    "\n",
    "        # --- Step 2: Run Analysis ---\n",
    "        processed_spot_df = analyze_anomalies(spot_df, \"Spot\")\n",
    "        suspicious_options_activity = analyze_suspicious_options(options_df_list)\n",
    "        \n",
    "        # --- Step 3: Visualize Results ---\n",
    "        plot_full_analysis(\n",
    "            stock_df=processed_spot_df,\n",
    "            futures_df=futures_df,\n",
    "            suspicious_options=suspicious_options_activity,\n",
    "            stock_name=STOCK_NAME,\n",
    "            target_date=TARGET_DATE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b62a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d2afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
